{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Introduction to Natural Language Processing or NLP\n",
    "\n",
    "\"\"\"\n",
    "Natural Language Processing, or NLP for short, focuses on analyzing text and speech data. This can range from simple recognition (what words are in the given text/speech), to sentiment analysis (was a review positive or negative), and all the way to areas like text generation (creating novel song lyrics from scratch).\n",
    "\n",
    "We’ll focus only on text in these lessons and not speech, but many of the same principles apply.\n",
    "\n",
    "NLP got its start mostly on machine translation, where users often had to create strict, manual rules to go from one language to another. It has since morphed to be more machine learning-based, reliant on much larger datasets than the early methods were.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-reset",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Tokenization and Embeddings\n",
    "\n",
    "\"\"\"\n",
    "help convert input text into useful data for input into the neural network layers\n",
    "\"\"\"\n",
    "\n",
    "###Recurrent Neural Networks (such as the LSTMs) as well as Text Generation\n",
    "\n",
    "\"\"\"\n",
    "allows for the creation of new text\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Tokenization: a way to represent letters or words in numerical format for input into a neural network\n",
    "\n",
    "Embeddings: how the neural network will internalise representations of different words\n",
    "\n",
    "Recurrent Neural Networks: able to handle sequences of data to consider words in context\n",
    "\n",
    "Test Generation: how to use networks to generate new text such selects for made-up song\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-modem",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Neural networks utilize numbers as their inputs, so we need to convert our input text into numbers.\n",
    "\n",
    "Tokenization is the process of assigning numbers to our inputs, but there is more than one way to do this - should each letter have its own numerical token, each word, phrase, etc.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Tokenizer\n",
    "\n",
    "With TensorFlow, this is done easily through use of a Tokenizer, found within tf.keras.preprocessing.text. If you wanted only the first 10 most common words, you could initialize it like so:\n",
    "\"\"\"\n",
    "\n",
    "#tokenizer = Tokenizer(num_words=10)\n",
    "\n",
    "\"\"\"\n",
    "Fit on Texts\n",
    "\n",
    "Then, to fit the tokenizer to your inputs (in the below case a list of strings called sentences), you use .fit_on_texts():\n",
    "\"\"\"\n",
    "\n",
    "#tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "\"\"\"\n",
    "Text to Sequences\n",
    "\n",
    "From there, you can use the tokenizer to convert sentences into tokenized sequences:\n",
    "\"\"\"\n",
    "\n",
    "#tokenizer.texts_to_sequences(sentences)\n",
    "\n",
    "\"\"\"\n",
    "Out of Vocabulary Words\n",
    "\n",
    "However, new sentences may have new words that the tokenizer was not fit on. By default, the tokenizer will just ignore these words and not include them in the tokenized sequences. However, you can also add an “out of vocabulary”, or OOV, token to represent these words. This has to be specified when originally creating the Tokenizer object.\n",
    "\"\"\"\n",
    "\n",
    "#tokenizer = Tokenizer(num_words=20, oov_token=’OOV’)\n",
    "\n",
    "\"\"\"\n",
    "Viewing the Word Index\n",
    "\n",
    "Lastly, if you want to see how the tokenizer has mapped numbers to words, use the tokenizer.word_index property to see this mapping.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-hunger",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Why do we need OOV\n",
    "\n",
    "\"\"\"\n",
    "When training a neural network, you train the model with a known dataset and validate and predict with datasets that the model has not seen yet\n",
    "\n",
    "So it's very likely that the validation and prediction text will contain words that are not in the word index\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
