{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "There are a number of ways you might improve your text generation models:\n",
    "\n",
    "Using more data?\n",
    "Youâ€™ll need to consider memory and output size constraints\n",
    "Also consider using only top-k most common words\n",
    "Know your data - songs have many more words than a Tweet\n",
    "Keep tuning your model\n",
    "Add/subtract from layer sizes or embedding dimensions\n",
    "Use np.random.choice with the probabilities for more variance in predicted outputs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Optimizing the Text Generation Model\n",
    "\n",
    "#You've already done some amazing work with generating new songs, but so far we've seen some issues with repetition and a fair amount of incoherence.\n",
    "#By using more data and further tweaking the model, you'll be able to get improved results.\n",
    "#We'll once again use the Kaggle Song Lyrics Dataset here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "second-webcam",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Import TensorFlow and related functions\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Other imports for processing data\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "laughing-citizenship",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "###Get the Dataset\n",
    "\n",
    "#As noted above, we'll utilize the Song Lyrics dataset on Kaggle again.\n",
    "\n",
    "!wget --no-check-certificate \\\n",
    "    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n",
    "    -O /tmp/songdata.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sharp-banking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset from csv - just first 10 songs for now\n",
    "dataset = pd.read_csv('C:/Users/fortn/anaconda3/songdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-morrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "250 Songs\n",
    "Now we've seen a model trained on just a small sample of songs, and how this often leads to repetition as you get further along in trying to generate new text.\n",
    "Let's switch to using the 250 songs instead, and see if our output improves. This will actually be nearly 10K lines of lyrics, which should be sufficient.\n",
    "\n",
    "Note that we won't use the full dataset here as it will take up quite a bit of RAM and processing time, but you're welcome to try doing so on your own later.\n",
    "If interested, you'll likely want to use only some of the more common words for the Tokenizer, which will help shrink processing time and memory needed (or else you'd have an output array hundreds of thousands of words long).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-teacher",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "corporate-pittsburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_corpus(corpus, num_words=-1):\n",
    "  # Fit a Tokenizer on the corpus\n",
    "  if num_words > -1:\n",
    "    tokenizer = Tokenizer(num_words=num_words)\n",
    "  else:\n",
    "    tokenizer = Tokenizer()\n",
    "  tokenizer.fit_on_texts(corpus)\n",
    "  return tokenizer\n",
    "\n",
    "def create_lyrics_corpus(dataset, field):\n",
    "  # Remove all other punctuation\n",
    "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
    "  # Make it lowercase\n",
    "  dataset[field] = dataset[field].str.lower()\n",
    "  # Make it one long string to split by line\n",
    "  lyrics = dataset[field].str.cat()\n",
    "  corpus = lyrics.split('\\n')\n",
    "  # Remove any trailing whitespace\n",
    "  for l in range(len(corpus)):\n",
    "    corpus[l] = corpus[l].rstrip()\n",
    "  # Remove any empty lines\n",
    "  corpus = [l for l in corpus if l != '']\n",
    "\n",
    "  return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "chinese-scotland",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-fbdddccf8583>:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "def tokenize_corpus(corpus, num_words=-1):\n",
    "  # Fit a Tokenizer on the corpus\n",
    "  if num_words > -1:\n",
    "    tokenizer = Tokenizer(num_words=num_words)\n",
    "  else:\n",
    "    tokenizer = Tokenizer()\n",
    "  tokenizer.fit_on_texts(corpus)\n",
    "  return tokenizer\n",
    "\n",
    "# Read the dataset from csv - this time with 250 songs\n",
    "dataset = pd.read_csv('C:/Users/fortn/anaconda3/songdata.csv', dtype=str)[:250]\n",
    "# Create the corpus using the 'text' column containing lyrics\n",
    "corpus = create_lyrics_corpus(dataset, 'text')\n",
    "# Tokenize the corpus\n",
    "tokenizer = tokenize_corpus(corpus, num_words=2000)\n",
    "total_words = tokenizer.num_words\n",
    "\n",
    "# There should be a lot more words now\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "through-bennett",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Create Sequences and Labels\n",
    "\n",
    "sequences = []\n",
    "for line in corpus:\n",
    "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
    "\tfor i in range(1, len(token_list)):\n",
    "\t\tn_gram_sequence = token_list[:i+1]\n",
    "\t\tsequences.append(n_gram_sequence)\n",
    "\n",
    "# Pad sequences for equal input length \n",
    "max_sequence_len = max([len(seq) for seq in sequences])\n",
    "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
    "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
    "# One-hot encode the labels\n",
    "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train a (Better) Text Generation Model\n",
    "With more data, we'll cut off after 100 epochs to avoid keeping you here all day.\n",
    "#You'll also want to change your runtime type to GPU if you haven't already (you'll need to re-run the above cells if you change runtimes).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-contrast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1480/1480 [==============================] - 44s 19ms/step - loss: 6.2311 - accuracy: 0.0404\n",
      "Epoch 2/100\n",
      "1480/1480 [==============================] - 28s 19ms/step - loss: 5.6895 - accuracy: 0.0477\n",
      "Epoch 3/100\n",
      "1480/1480 [==============================] - 28s 19ms/step - loss: 5.4754 - accuracy: 0.0702\n",
      "Epoch 4/100\n",
      "1480/1480 [==============================] - 37s 25ms/step - loss: 5.2980 - accuracy: 0.0919\n",
      "Epoch 5/100\n",
      "1480/1480 [==============================] - 34s 23ms/step - loss: 5.1024 - accuracy: 0.1141\n",
      "Epoch 6/100\n",
      "1480/1480 [==============================] - 31s 21ms/step - loss: 4.8992 - accuracy: 0.1361\n",
      "Epoch 7/100\n",
      "1480/1480 [==============================] - 32s 22ms/step - loss: 4.7278 - accuracy: 0.15500s - loss:\n",
      "Epoch 8/100\n",
      "1480/1480 [==============================] - 33s 22ms/step - loss: 4.5808 - accuracy: 0.1679\n",
      "Epoch 9/100\n",
      "1480/1480 [==============================] - 35s 24ms/step - loss: 4.4686 - accuracy: 0.17750s - loss:\n",
      "Epoch 10/100\n",
      "1480/1480 [==============================] - 34s 23ms/step - loss: 4.3671 - accuracy: 0.1886\n",
      "Epoch 11/100\n",
      "1480/1480 [==============================] - 29s 20ms/step - loss: 4.2562 - accuracy: 0.2024\n",
      "Epoch 12/100\n",
      "1480/1480 [==============================] - 31s 21ms/step - loss: 4.1748 - accuracy: 0.2145\n",
      "Epoch 13/100\n",
      "1480/1480 [==============================] - 28s 19ms/step - loss: 4.1057 - accuracy: 0.2206\n",
      "Epoch 14/100\n",
      "1480/1480 [==============================] - 26s 17ms/step - loss: 4.0195 - accuracy: 0.2336\n",
      "Epoch 15/100\n",
      "1480/1480 [==============================] - 29s 19ms/step - loss: 3.9566 - accuracy: 0.2409\n",
      "Epoch 16/100\n",
      "1480/1480 [==============================] - 39s 26ms/step - loss: 3.7667 - accuracy: 0.2661 ETA: 0s - loss: 3.7664 - ac\n",
      "Epoch 19/100\n",
      "1480/1480 [==============================] - 38s 25ms/step - loss: 3.7061 - accuracy: 0.2750\n",
      "Epoch 20/100\n",
      "1480/1480 [==============================] - 32s 22ms/step - loss: 3.6783 - accuracy: 0.2782\n",
      "Epoch 21/100\n",
      "1480/1480 [==============================] - 31s 21ms/step - loss: 3.6314 - accuracy: 0.2868\n",
      "Epoch 22/100\n",
      "1480/1480 [==============================] - 35s 24ms/step - loss: 3.5748 - accuracy: 0.2920\n",
      "Epoch 23/100\n",
      "1480/1480 [==============================] - 31s 21ms/step - loss: 3.5396 - accuracy: 0.2987\n",
      "Epoch 24/100\n",
      "1480/1480 [==============================] - 34s 23ms/step - loss: 3.5180 - accuracy: 0.3026\n",
      "Epoch 25/100\n",
      "1480/1480 [==============================] - 30s 20ms/step - loss: 3.4764 - accuracy: 0.3124\n",
      "Epoch 26/100\n",
      "1480/1480 [==============================] - 28s 19ms/step - loss: 3.4325 - accuracy: 0.3165\n",
      "Epoch 27/100\n",
      "1480/1480 [==============================] - 32s 22ms/step - loss: 3.3821 - accuracy: 0.3246\n",
      "Epoch 28/100\n",
      "1480/1480 [==============================] - 34s 23ms/step - loss: 3.3727 - accuracy: 0.3236\n",
      "Epoch 29/100\n",
      "1480/1480 [==============================] - 33s 22ms/step - loss: 3.3548 - accuracy: 0.32680s - loss:\n",
      "Epoch 30/100\n",
      "1480/1480 [==============================] - 36s 24ms/step - loss: 3.3006 - accuracy: 0.3369\n",
      "Epoch 31/100\n",
      "1480/1480 [==============================] - 30s 20ms/step - loss: 3.2803 - accuracy: 0.3379\n",
      "Epoch 32/100\n",
      "1480/1480 [==============================] - 32s 21ms/step - loss: 3.2360 - accuracy: 0.3438\n",
      "Epoch 33/100\n",
      "1480/1480 [==============================] - 30s 20ms/step - loss: 3.2360 - accuracy: 0.3486\n",
      "Epoch 34/100\n",
      "1480/1480 [==============================] - 28s 19ms/step - loss: 3.2082 - accuracy: 0.3486\n",
      "Epoch 35/100\n",
      "1480/1480 [==============================] - 27s 19ms/step - loss: 3.1501 - accuracy: 0.3579\n",
      "Epoch 36/100\n",
      "1480/1480 [==============================] - 29s 19ms/step - loss: 3.1552 - accuracy: 0.3596\n",
      "Epoch 37/100\n",
      "1480/1480 [==============================] - 29s 20ms/step - loss: 3.1006 - accuracy: 0.3679\n",
      "Epoch 38/100\n",
      "1480/1480 [==============================] - 29s 20ms/step - loss: 3.0997 - accuracy: 0.3658\n",
      "Epoch 39/100\n",
      "1480/1480 [==============================] - 33s 22ms/step - loss: 3.0606 - accuracy: 0.37252s - loss: 3.0586 - accura - ETA: 1s - los - ETA\n",
      "Epoch 40/100\n",
      "1480/1480 [==============================] - 31s 21ms/step - loss: 3.0473 - accuracy: 0.3778\n",
      "Epoch 41/100\n",
      "1480/1480 [==============================] - 30s 20ms/step - loss: 3.0242 - accuracy: 0.3794\n",
      "Epoch 42/100\n",
      "1480/1480 [==============================] - 28s 19ms/step - loss: 3.0124 - accuracy: 0.3805\n",
      "Epoch 43/100\n",
      "1480/1480 [==============================] - 30s 20ms/step - loss: 2.9914 - accuracy: 0.38640s - loss: 2.9912 - accu\n",
      "Epoch 44/100\n",
      "1480/1480 [==============================] - 31s 21ms/step - loss: 2.9986 - accuracy: 0.3812\n",
      "Epoch 45/100\n",
      "1480/1480 [==============================] - 28s 19ms/step - loss: 2.9441 - accuracy: 0.39270s\n",
      "Epoch 46/100\n",
      "1480/1480 [==============================] - 28s 19ms/step - loss: 2.9251 - accuracy: 0.3970\n",
      "Epoch 47/100\n",
      "1480/1480 [==============================] - 27s 18ms/step - loss: 2.8963 - accuracy: 0.4017\n",
      "Epoch 48/100\n",
      "1480/1480 [==============================] - 27s 18ms/step - loss: 2.9138 - accuracy: 0.3970\n",
      "Epoch 49/100\n",
      "1480/1480 [==============================] - 27s 18ms/step - loss: 2.8587 - accuracy: 0.4059\n",
      "Epoch 50/100\n",
      "1480/1480 [==============================] - 27s 18ms/step - loss: 2.8588 - accuracy: 0.4051\n",
      "Epoch 51/100\n",
      "1480/1480 [==============================] - 27s 18ms/step - loss: 2.8405 - accuracy: 0.4079\n",
      "Epoch 52/100\n",
      "1480/1480 [==============================] - 26s 18ms/step - loss: 2.8378 - accuracy: 0.4089\n",
      "Epoch 53/100\n",
      "1480/1480 [==============================] - 27s 18ms/step - loss: 2.8252 - accuracy: 0.4150\n",
      "Epoch 54/100\n",
      "1480/1480 [==============================] - 28s 19ms/step - loss: 2.7936 - accuracy: 0.4145\n",
      "Epoch 55/100\n",
      "1480/1480 [==============================] - 37s 25ms/step - loss: 2.7878 - accuracy: 0.41920s - loss: 2.7875 - ac\n",
      "Epoch 56/100\n",
      "1480/1480 [==============================] - 38s 26ms/step - loss: 2.7528 - accuracy: 0.4252\n",
      "Epoch 57/100\n",
      "1480/1480 [==============================] - 33s 23ms/step - loss: 2.7659 - accuracy: 0.4221\n",
      "Epoch 58/100\n",
      "1480/1480 [==============================] - 35s 24ms/step - loss: 2.7290 - accuracy: 0.4266\n",
      "Epoch 59/100\n",
      "1480/1480 [==============================] - 30s 20ms/step - loss: 2.7406 - accuracy: 0.4252\n",
      "Epoch 60/100\n",
      "1480/1480 [==============================] - 34s 23ms/step - loss: 2.7226 - accuracy: 0.43050s - loss: 2.7225 - accuracy: 0.\n",
      "Epoch 61/100\n",
      "1480/1480 [==============================] - 32s 22ms/step - loss: 2.7213 - accuracy: 0.4269\n",
      "Epoch 62/100\n",
      "1480/1480 [==============================] - 35s 24ms/step - loss: 2.6789 - accuracy: 0.4382\n",
      "Epoch 63/100\n",
      "1480/1480 [==============================] - 30s 21ms/step - loss: 2.6659 - accuracy: 0.4392\n",
      "Epoch 64/100\n",
      "1480/1480 [==============================] - 33s 22ms/step - loss: 2.6795 - accuracy: 0.4361\n",
      "Epoch 65/100\n",
      "1480/1480 [==============================] - 33s 22ms/step - loss: 2.6573 - accuracy: 0.4401\n",
      "Epoch 66/100\n",
      "1480/1480 [==============================] - 39s 27ms/step - loss: 2.6441 - accuracy: 0.4408\n",
      "Epoch 67/100\n",
      "1480/1480 [==============================] - 34s 23ms/step - loss: 2.6307 - accuracy: 0.44160s -\n",
      "Epoch 68/100\n",
      "1480/1480 [==============================] - 34s 23ms/step - loss: 2.6229 - accuracy: 0.4454\n",
      "Epoch 69/100\n",
      "1480/1480 [==============================] - 33s 22ms/step - loss: 2.6230 - accuracy: 0.44520s - loss: 2.622\n",
      "Epoch 70/100\n",
      "1480/1480 [==============================] - 44s 29ms/step - loss: 2.6129 - accuracy: 0.4446\n",
      "Epoch 71/100\n",
      "1480/1480 [==============================] - 50s 34ms/step - loss: 2.5926 - accuracy: 0.4497\n",
      "Epoch 72/100\n",
      "1480/1480 [==============================] - 46s 31ms/step - loss: 2.5742 - accuracy: 0.4578\n",
      "Epoch 73/100\n",
      "1480/1480 [==============================] - 38s 26ms/step - loss: 2.5505 - accuracy: 0.45761s - loss: 2.549 - ETA: 0s - loss: 2.5503 - \n",
      "Epoch 77/100\n",
      "1480/1480 [==============================] - 42s 29ms/step - loss: 2.5414 - accuracy: 0.4597\n",
      "Epoch 78/100\n",
      "1480/1480 [==============================] - 41s 28ms/step - loss: 2.4695 - accuracy: 0.4714\n",
      "Epoch 84/100\n",
      "1480/1480 [==============================] - 43s 29ms/step - loss: 2.4813 - accuracy: 0.4681\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1480/1480 [==============================] - 39s 27ms/step - loss: 2.4241 - accuracy: 0.4831\n",
      "Epoch 91/100\n",
      "1480/1480 [==============================] - 39s 27ms/step - loss: 2.4017 - accuracy: 0.4844\n",
      "Epoch 92/100\n",
      "1480/1480 [==============================] - 43s 29ms/step - loss: 2.4100 - accuracy: 0.4835\n",
      "Epoch 93/100\n",
      "1480/1480 [==============================] - 43s 29ms/step - loss: 2.3904 - accuracy: 0.4875\n",
      "Epoch 94/100\n",
      "1480/1480 [==============================] - 46s 31ms/step - loss: 2.3733 - accuracy: 0.4885\n",
      "Epoch 99/100\n",
      "1480/1480 [==============================] - 46s 31ms/step - loss: 2.3717 - accuracy: 0.4902\n",
      "Epoch 100/100\n",
      "1263/1480 [========================>.....] - ETA: 7s - loss: 2.3686 - accuracy: 0.4953"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(20)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(input_sequences, one_hot_labels, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "nervous-strategy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###View the Training Graph\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.show()\n",
    "\n",
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Generate better lyrics!\n",
    "#This time around, we should be able to get a more interesting output with less repetition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "above-taiwan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im feeling chills me to the bone on the sky and shining out of your misery famous beams meets beach bliss apple complain girls wonderful teach heavens changed fat adore hero word showing small cotton age knock missing give me the other inside is the same again and you and me jeanie jeanie is until youre gonna take for me im extra fucking wasted i know we get to me jeanie on my head livin like you want to go away from sing the girls around before you shouldnt me jeanie jeanie again for the night is sleep o river before you dance\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"im feeling chills\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "\toutput_word = \"\"\n",
    "\tfor word, index in tokenizer.word_index.items():\n",
    "\t\tif index == predicted:\n",
    "\t\t\toutput_word = word\n",
    "\t\t\tbreak\n",
    "\tseed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-costume",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Varying the Possible Outputs\n",
    "In running the above, you may notice that the same seed text will generate similar outputs.\n",
    "This is because the code is currently always choosing the top predicted class as the next word.\n",
    "What if you wanted more variance in the output?\n",
    "\n",
    "Switching from model.predict_classes to model.predict_proba will get us all of the class probabilities.\n",
    "We can combine this with np.random.choice to select a given predicted output based on a probability, thereby giving a bit more randomness to our outputs.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "unavailable-giant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "# Test the method with just the first word after the seed text\n",
    "seed_text = \"im feeling chills\"\n",
    "next_words = 100\n",
    "  \n",
    "token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "predicted_probs = model.predict(token_list)[0]\n",
    "predicted = np.random.choice([x for x in range(len(predicted_probs))], \n",
    "                             p=predicted_probs)\n",
    "# Running this cell multiple times should get you some variance in output\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "impossible-pharmaceutical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im feeling chills in your will for him this time but i please me aint no crazy night after long night late changed out that street knew office cutie teach lovelight shoes light back upon the moon shine that beats to blame for no easy that i will love up your mother know i is no more to be your more mans dust too funny call us gee shes fat of judge live prison run sore very parted gotta kin fire for love then you kissed the back to begun that trick now is the park of rock women clouds age mama rocking\n"
     ]
    }
   ],
   "source": [
    "# Use this process for the full output generation\n",
    "seed_text = \"im feeling chills\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "  predicted_probs = model.predict(token_list)[0]\n",
    "  predicted = np.random.choice([x for x in range(len(predicted_probs))],\n",
    "                               p=predicted_probs)\n",
    "  output_word = \"\"\n",
    "  for word, index in tokenizer.word_index.items():\n",
    "    if index == predicted:\n",
    "      output_word = word\n",
    "      break\n",
    "  seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-positive",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
